
# Troubleshooting Fix â€” Deep Learning with TensorFlow

This notebook demonstrates the debugging of a TensorFlow CNN model for classifying MNIST handwritten digits.

We will identify and fix common issues like:
- Input shape mismatches
- Incorrect loss functions
- Wrong output activation functions

# Install if necessary
# !pip install tensorflow matplotlib

import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense
from tensorflow.keras.datasets import mnist
import matplotlib.pyplot as plt
import numpy as np


# Load the MNIST dataset
(x_train, y_train), (x_test, y_test) = mnist.load_data()

# Check data shape
print("Training data shape:", x_train.shape)
print("Testing data shape:", x_test.shape)


## Buggy Code Example:
Below is an incorrect implementation where:
- The input shape for Conv2D is missing the channel dimension.
- The loss function is `categorical_crossentropy` while labels are integers (should use `sparse_categorical_crossentropy`).

# Buggy Model: This will cause a shape mismatch error

try:
    buggy_model = Sequential()
    buggy_model.add(Conv2D(32, (3,3), activation='relu', input_shape=(28,28)))  # Missing channel dimension
    buggy_model.add(Flatten())
    buggy_model.add(Dense(10, activation='softmax'))
    buggy_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

    # This will fail due to shape mismatch
    buggy_model.fit(x_train, y_train, epochs=1)
except Exception as e:
    print("Error:", e)

## Fix: Data Preprocessing
- Reshape data to add channel dimension (28,28,1)
- Normalize pixel values to 0-1

# Reshape data to add channel dimension
x_train = x_train.reshape((-1, 28, 28, 1))
x_test = x_test.reshape((-1, 28, 28, 1))

# Normalize pixel values
x_train, x_test = x_train / 255.0, x_test / 255.0

# Corrected CNN Model
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Flatten())
model.add(Dense(128, activation='relu'))
model.add(Dense(10, activation='softmax'))

# Compile with correct loss function
model.compile(optimizer='adam', 
              loss='sparse_categorical_crossentropy', 
              metrics=['accuracy'])

# Train the corrected model
model.fit(x_train, y_train, epochs=3, batch_size=64, validation_split=0.1)

# Evaluate on test set
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print("Test Accuracy:", test_accuracy)

# Predict and visualize 5 random test images
predictions = model.predict(x_test)

for i in range(5):
    plt.imshow(x_test[i].reshape(28,28), cmap='gray')
    plt.title(f"Predicted: {np.argmax(predictions[i])}, Actual: {y_test[i]}")
    plt.axis('off')
    plt.show()


